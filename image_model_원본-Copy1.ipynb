{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3ea60f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "597c9eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['상의']\n"
     ]
    }
   ],
   "source": [
    "# 데이터가 많으므로 테스트에서는 1000건만 처리하도록 한다.\n",
    "NUM_ROWS = 1000\n",
    "\n",
    "DATASET_PATH = 'C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷'\n",
    "print(os.listdir(DATASET_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d2eb3b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/101.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>102.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/102.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>103.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/103.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>104.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/104.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>105.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/105.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>106.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/106.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  \\\n",
       "0    0.jpg   \n",
       "1    1.jpg   \n",
       "2   10.jpg   \n",
       "3  100.jpg   \n",
       "4  101.jpg   \n",
       "5  102.jpg   \n",
       "6  103.jpg   \n",
       "7  104.jpg   \n",
       "8  105.jpg   \n",
       "9  106.jpg   \n",
       "\n",
       "                                                                  image  \n",
       "0    C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/0.jpg  \n",
       "1    C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/1.jpg  \n",
       "2   C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/10.jpg  \n",
       "3  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/100.jpg  \n",
       "4  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/101.jpg  \n",
       "5  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/102.jpg  \n",
       "6  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/103.jpg  \n",
       "7  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/104.jpg  \n",
       "8  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/105.jpg  \n",
       "9  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷/상의/106.jpg  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = []\n",
    "filenames = []\n",
    "images = []\n",
    "\n",
    "pd.set_option('display.max_colwidth', None) # None을 사용하면 전체 내용이 표시됩니다.\n",
    "\n",
    "df = pd.DataFrame(columns=['filename', 'image'])\n",
    "for folder in os.listdir(DATASET_PATH):\n",
    "    folder_path = os.path.join(DATASET_PATH, folder)\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        filenames.append(file)\n",
    "        images.append(os.path.join(DATASET_PATH, folder, file).replace('\\\\','/'))\n",
    "\n",
    "\n",
    "df['filename'] = filenames\n",
    "df['image'] = images\n",
    "\n",
    "df = df[:NUM_ROWS]\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "949222ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딕셔너리 데이터를 인자값을 받아서 이미지를 출력한다.\n",
    "def plot_figures(figures, nrows = 1, ncols=1,figsize=(5, 3)):\n",
    "    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=figsize)\n",
    "    for ind,title in enumerate(figures):\n",
    "        axeslist.ravel()[ind].imshow(cv2.cvtColor(figures[title], cv2.COLOR_BGR2RGB))\n",
    "        axeslist.ravel()[ind].set_title(title)\n",
    "        axeslist.ravel()[ind].set_axis_off()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "353db0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 경로를 읽어서 numpy로 변환한다.\n",
    "# 기본 0.1 비율로 리사이즈를 처리한다.\n",
    "def load_image(img_path, resized_fac = 0.1):\n",
    "    img  = cv2.imread(img_path)\n",
    "    w, h, _ = img.shape\n",
    "    resized = cv2.resize(img, (int(h*resized_fac), int(w*resized_fac)), interpolation = cv2.INTER_AREA)\n",
    "    return resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "865a5030",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m figures \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) : load_image(row\u001b[38;5;241m.\u001b[39mimage) \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39miterrows()}\n\u001b[0;32m      2\u001b[0m figures\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m      3\u001b[0m plot_figures(figures, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[1;32mIn[83], line 1\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m figures \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) : \u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39miterrows()}\n\u001b[0;32m      2\u001b[0m figures\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m      3\u001b[0m plot_figures(figures, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[1;32mIn[82], line 5\u001b[0m, in \u001b[0;36mload_image\u001b[1;34m(img_path, resized_fac)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_image\u001b[39m(img_path, resized_fac \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m):\n\u001b[0;32m      4\u001b[0m     img  \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[1;32m----> 5\u001b[0m     w, h, _ \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[0;32m      6\u001b[0m     resized \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (\u001b[38;5;28mint\u001b[39m(h\u001b[38;5;241m*\u001b[39mresized_fac), \u001b[38;5;28mint\u001b[39m(w\u001b[38;5;241m*\u001b[39mresized_fac)), interpolation \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mINTER_AREA)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resized\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "figures = {'sample'+ str(i) : load_image(row.image) for i, row in df.sample(6).iterrows()}\n",
    "figures.keys()\n",
    "plot_figures(figures, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3e5c833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "# from keras.preprocessing import image\n",
    "import keras.utils as image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f3088e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 8s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 2048)              0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23587712 (89.98 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 입력 이미지\n",
    "\n",
    "img_width, img_height, img_channel = 224, 224, 3\n",
    "\n",
    "# 훈련된 모델 사용\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape = (img_width, img_height, img_channel))\n",
    "base_model.trainable = False\n",
    "\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    GlobalMaxPooling2D()\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2def4c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 임베딩\n",
    "def get_embedding(model, img_path):\n",
    "    # Pillow 이미지 로드\n",
    "    img = image.load_img(img_path, target_size=(img_width, img_height))\n",
    "    # numpy 데이터로 변환 (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # 차원을 추가해준다. (1, 224, 224, 3)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    # 1차원의 배열로 재배열해준다. [[5.232, 2.12, ...]] -> [5.232, 2.12, ...]\n",
    "    return model.predict(x).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a651a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷\\\\상의\\\\523.jpg'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c334c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 851ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 행 이미지 임베딩을 출력\n",
    "emb = get_embedding(model, df.iloc[0].image)\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29df4919",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 첫 행 이미지 시각화\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m img_array \u001b[38;5;241m=\u001b[39m \u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(cv2\u001b[38;5;241m.\u001b[39mcvtColor(img_array, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n",
      "Cell \u001b[1;32mIn[29], line 5\u001b[0m, in \u001b[0;36mload_image\u001b[1;34m(img_path, resized_fac)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_image\u001b[39m(img_path, resized_fac \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m):\n\u001b[0;32m      4\u001b[0m     img  \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[1;32m----> 5\u001b[0m     w, h, _ \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[0;32m      6\u001b[0m     resized \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (\u001b[38;5;28mint\u001b[39m(h\u001b[38;5;241m*\u001b[39mresized_fac), \u001b[38;5;28mint\u001b[39m(w\u001b[38;5;241m*\u001b[39mresized_fac)), interpolation \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mINTER_AREA)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resized\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# 첫 행 이미지 시각화\n",
    "img_array = load_image(df.iloc[0].image)\n",
    "plt.figure(figsize = (2,2))\n",
    "plt.imshow(cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB))\n",
    "print(img_array.shape)\n",
    "print(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24570f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "1it [00:00, 1002.46it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:6\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\std.py:814\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(df, df_function)(wrapper, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    816\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\std.py:809\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    804\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[0;32m    808\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m<timed exec>:6\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(img)\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "tqdm_pandas(tqdm())\n",
    "\n",
    "# 전체 데이터 임베딩\n",
    "df_sample = df\n",
    "map_embeddings = df_sample['image'].progress_apply(lambda img: get_embedding(model, img))\n",
    "df_embs = map_embeddings.apply(pd.Series)\n",
    "\n",
    "print(df_embs.shape)\n",
    "df_embs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "769624cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aecd8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# cosine 거리 계산\n",
    "pairwise_distances(df_embs, metric='cosine')\n",
    "\n",
    "# 정규화\n",
    "cosine_sim = 1 - pairwise_distances(df_embs, metric='cosine')\n",
    "cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8245348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사한 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7276e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(range(len(df)), index=df.index)\n",
    "\n",
    "def get_recommender(idx, df, top_n = 5):\n",
    "    sim_idx = indices[idx]\n",
    "    sim_scores = list(enumerate(cosine_sim[sim_idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:top_n+1]\n",
    "    idx_rec    = [i[0] for i in sim_scores]\n",
    "    idx_sim    = [i[1] for i in sim_scores]\n",
    "\n",
    "    return indices.iloc[idx_rec].index, idx_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e88494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사한 데이터 출력해보기\n",
    "idx_ref = 1\n",
    "idx_rec, idx_sim = get_recommender(idx_ref, df, top_n = 6)\n",
    "\n",
    "plt.figure(figsize = (2,2))\n",
    "plt.imshow(cv2.cvtColor(load_image(df.iloc[idx_ref].image), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "figures = {'img-'+str(i): load_image(row.image) for i, row in df.loc[idx_rec].iterrows()}\n",
    "plot_figures(figures, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324fa2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d11e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
