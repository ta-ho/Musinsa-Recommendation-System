{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ea60f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "597c9eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.jpg', '1.jpg', '10.jpg', '100.jpg', '101.jpg', '102.jpg', '103.jpg', '104.jpg', '105.jpg', '106.jpg', '107.jpg', '108.jpg', '109.jpg', '11.jpg', '110.jpg', '111.jpg', '112.jpg', '113.jpg', '114.jpg', '115.jpg', '116.jpg', '117.jpg', '118.jpg', '119.jpg', '12.jpg', '120.jpg', '121.jpg', '122.jpg', '123.jpg', '124.jpg', '125.jpg', '126.jpg', '127.jpg', '128.jpg', '129.jpg', '13.jpg', '130.jpg', '131.jpg', '132.jpg', '133.jpg', '134.jpg', '135.jpg', '136.jpg', '137.jpg', '138.jpg', '139.jpg', '14.jpg', '140.jpg', '141.jpg', '142.jpg', '143.jpg', '144.jpg', '145.jpg', '146.jpg', '147.jpg', '148.jpg', '149.jpg', '15.jpg', '150.jpg', '151.jpg', '152.jpg', '153.jpg', '154.jpg', '155.jpg', '156.jpg', '157.jpg', '158.jpg', '159.jpg', '16.jpg', '160.jpg', '161.jpg', '162.jpg', '163.jpg', '164.jpg', '165.jpg', '166.jpg', '167.jpg', '168.jpg', '169.jpg', '17.jpg', '170.jpg', '171.jpg', '172.jpg', '173.jpg', '174.jpg', '175.jpg', '176.jpg', '177.jpg', '178.jpg', '179.jpg', '18.jpg', '180.jpg', '181.jpg', '182.jpg', '183.jpg', '184.jpg', '185.jpg', '186.jpg', '187.jpg', '188.jpg', '189.jpg', '19.jpg', '190.jpg', '191.jpg', '192.jpg', '193.jpg', '194.jpg', '195.jpg', '196.jpg', '197.jpg', '198.jpg', '199.jpg', '2.jpg', '20.jpg', '200.jpg', '201.jpg', '202.jpg', '203.jpg', '204.jpg', '205.jpg', '206.jpg', '207.jpg', '208.jpg', '209.jpg', '21.jpg', '210.jpg', '211.jpg', '212.jpg', '213.jpg', '214.jpg', '215.jpg', '216.jpg', '217.jpg', '218.jpg', '219.jpg', '22.jpg', '220.jpg', '221.jpg', '222.jpg', '223.jpg', '224.jpg', '225.jpg', '226.jpg', '227.jpg', '228.jpg', '229.jpg', '23.jpg', '230.jpg', '231.jpg', '232.jpg', '233.jpg', '234.jpg', '235.jpg', '236.jpg', '237.jpg', '238.jpg', '239.jpg', '24.jpg', '240.jpg', '241.jpg', '242.jpg', '243.jpg', '244.jpg', '245.jpg', '246.jpg', '247.jpg', '248.jpg', '249.jpg', '25.jpg', '250.jpg', '251.jpg', '252.jpg', '253.jpg', '254.jpg', '255.jpg', '256.jpg', '257.jpg', '258.jpg', '259.jpg', '26.jpg', '260.jpg', '261.jpg', '262.jpg', '263.jpg', '264.jpg', '265.jpg', '266.jpg', '267.jpg', '268.jpg', '269.jpg', '27.jpg', '270.jpg', '271.jpg', '272.jpg', '273.jpg', '274.jpg', '275.jpg', '276.jpg', '277.jpg', '278.jpg', '279.jpg', '28.jpg', '280.jpg', '281.jpg', '282.jpg', '283.jpg', '284.jpg', '285.jpg', '286.jpg', '287.jpg', '288.jpg', '289.jpg', '29.jpg', '290.jpg', '291.jpg', '292.jpg', '293.jpg', '294.jpg', '295.jpg', '296.jpg', '297.jpg', '298.jpg', '299.jpg', '3.jpg', '30.jpg', '300.jpg', '301.jpg', '302.jpg', '303.jpg', '304.jpg', '305.jpg', '306.jpg', '307.jpg', '308.jpg', '309.jpg', '31.jpg', '310.jpg', '311.jpg', '312.jpg', '313.jpg', '314.jpg', '315.jpg', '316.jpg', '317.jpg', '318.jpg', '319.jpg', '32.jpg', '320.jpg', '321.jpg', '322.jpg', '323.jpg', '324.jpg', '325.jpg', '326.jpg', '327.jpg', '328.jpg', '329.jpg', '33.jpg', '330.jpg', '331.jpg', '332.jpg', '333.jpg', '334.jpg', '335.jpg', '336.jpg', '337.jpg', '338.jpg', '339.jpg', '34.jpg', '340.jpg', '341.jpg', '342.jpg', '343.jpg', '344.jpg', '345.jpg', '346.jpg', '347.jpg', '348.jpg', '349.jpg', '35.jpg', '350.jpg', '351.jpg', '352.jpg', '353.jpg', '354.jpg', '355.jpg', '356.jpg', '357.jpg', '358.jpg', '359.jpg', '36.jpg', '360.jpg', '361.jpg', '362.jpg', '363.jpg', '364.jpg', '365.jpg', '366.jpg', '367.jpg', '368.jpg', '369.jpg', '37.jpg', '370.jpg', '371.jpg', '372.jpg', '373.jpg', '374.jpg', '375.jpg', '376.jpg', '377.jpg', '378.jpg', '379.jpg', '38.jpg', '380.jpg', '381.jpg', '382.jpg', '383.jpg', '384.jpg', '385.jpg', '386.jpg', '387.jpg', '388.jpg', '389.jpg', '39.jpg', '390.jpg', '391.jpg', '392.jpg', '393.jpg', '394.jpg', '395.jpg', '396.jpg', '397.jpg', '398.jpg', '399.jpg', '4.jpg', '40.jpg', '400.jpg', '401.jpg', '402.jpg', '403.jpg', '404.jpg', '405.jpg', '406.jpg', '407.jpg', '408.jpg', '409.jpg', '41.jpg', '410.jpg', '411.jpg', '412.jpg', '413.jpg', '414.jpg', '415.jpg', '416.jpg', '417.jpg', '418.jpg', '419.jpg', '42.jpg', '420.jpg', '421.jpg', '422.jpg', '423.jpg', '424.jpg', '425.jpg', '426.jpg', '427.jpg', '428.jpg', '429.jpg', '43.jpg', '430.jpg', '431.jpg', '432.jpg', '433.jpg', '434.jpg', '435.jpg', '436.jpg', '437.jpg', '438.jpg', '439.jpg', '44.jpg', '440.jpg', '441.jpg', '442.jpg', '443.jpg', '444.jpg', '445.jpg', '446.jpg', '447.jpg', '448.jpg', '449.jpg', '45.jpg', '450.jpg', '451.jpg', '452.jpg', '453.jpg', '454.jpg', '455.jpg', '456.jpg', '457.jpg', '458.jpg', '459.jpg', '46.jpg', '460.jpg', '461.jpg', '462.jpg', '463.jpg', '464.jpg', '465.jpg', '466.jpg', '467.jpg', '468.jpg', '469.jpg', '47.jpg', '470.jpg', '471.jpg', '472.jpg', '473.jpg', '474.jpg', '475.jpg', '476.jpg', '477.jpg', '478.jpg', '479.jpg', '48.jpg', '480.jpg', '481.jpg', '482.jpg', '483.jpg', '484.jpg', '485.jpg', '486.jpg', '487.jpg', '488.jpg', '489.jpg', '49.jpg', '490.jpg', '491.jpg', '492.jpg', '493.jpg', '494.jpg', '495.jpg', '496.jpg', '497.jpg', '498.jpg', '499.jpg', '5.jpg', '50.jpg', '500.jpg', '501.jpg', '502.jpg', '503.jpg', '504.jpg', '505.jpg', '506.jpg', '507.jpg', '508.jpg', '509.jpg', '51.jpg', '510.jpg', '511.jpg', '512.jpg', '513.jpg', '514.jpg', '515.jpg', '516.jpg', '517.jpg', '518.jpg', '519.jpg', '52.jpg', '520.jpg', '521.jpg', '522.jpg', '523.jpg', '524.jpg', '525.jpg', '526.jpg', '527.jpg', '528.jpg', '529.jpg', '53.jpg', '530.jpg', '531.jpg', '532.jpg', '533.jpg', '534.jpg', '535.jpg', '536.jpg', '537.jpg', '538.jpg', '539.jpg', '54.jpg', '540.jpg', '541.jpg', '542.jpg', '543.jpg', '544.jpg', '545.jpg', '546.jpg', '547.jpg', '548.jpg', '549.jpg', '55.jpg', '550.jpg', '551.jpg', '552.jpg', '553.jpg', '554.jpg', '555.jpg', '556.jpg', '557.jpg', '558.jpg', '559.jpg', '56.jpg', '560.jpg', '561.jpg', '562.jpg', '563.jpg', '564.jpg', '565.jpg', '566.jpg', '567.jpg', '568.jpg', '569.jpg', '57.jpg', '570.jpg', '571.jpg', '572.jpg', '573.jpg', '574.jpg', '575.jpg', '576.jpg', '577.jpg', '578.jpg', '579.jpg', '58.jpg', '580.jpg', '581.jpg', '582.jpg', '583.jpg', '584.jpg', '585.jpg', '586.jpg', '587.jpg', '588.jpg', '589.jpg', '59.jpg', '590.jpg', '591.jpg', '592.jpg', '593.jpg', '594.jpg', '595.jpg', '596.jpg', '597.jpg', '598.jpg', '599.jpg', '6.jpg', '60.jpg', '600.jpg', '601.jpg', '602.jpg', '603.jpg', '604.jpg', '605.jpg', '606.jpg', '607.jpg', '608.jpg', '609.jpg', '61.jpg', '610.jpg', '611.jpg', '612.jpg', '613.jpg', '614.jpg', '615.jpg', '616.jpg', '617.jpg', '618.jpg', '619.jpg', '62.jpg', '620.jpg', '621.jpg', '622.jpg', '623.jpg', '624.jpg', '625.jpg', '626.jpg', '627.jpg', '628.jpg', '629.jpg', '63.jpg', '630.jpg', '631.jpg', '632.jpg', '633.jpg', '634.jpg', '635.jpg', '636.jpg', '637.jpg', '638.jpg', '639.jpg', '64.jpg', '640.jpg', '641.jpg', '642.jpg', '643.jpg', '644.jpg', '645.jpg', '646.jpg', '647.jpg', '648.jpg', '649.jpg', '65.jpg', '650.jpg', '651.jpg', '652.jpg', '653.jpg', '654.jpg', '655.jpg', '656.jpg', '657.jpg', '658.jpg', '659.jpg', '66.jpg', '660.jpg', '661.jpg', '662.jpg', '663.jpg', '664.jpg', '665.jpg', '666.jpg', '667.jpg', '668.jpg', '669.jpg', '67.jpg', '670.jpg', '671.jpg', '672.jpg', '673.jpg', '674.jpg', '675.jpg', '676.jpg', '677.jpg', '678.jpg', '679.jpg', '68.jpg', '680.jpg', '681.jpg', '682.jpg', '683.jpg', '684.jpg', '685.jpg', '686.jpg', '687.jpg', '688.jpg', '689.jpg', '69.jpg', '690.jpg', '691.jpg', '692.jpg', '693.jpg', '694.jpg', '695.jpg', '696.jpg', '697.jpg', '698.jpg', '699.jpg', '7.jpg', '70.jpg', '700.jpg', '701.jpg', '702.jpg', '703.jpg', '704.jpg', '705.jpg', '706.jpg', '707.jpg', '708.jpg', '709.jpg', '71.jpg', '710.jpg', '711.jpg', '712.jpg', '713.jpg', '714.jpg', '715.jpg', '716.jpg', '717.jpg', '718.jpg', '719.jpg', '72.jpg', '720.jpg', '721.jpg', '722.jpg', '723.jpg', '724.jpg', '725.jpg', '726.jpg', '727.jpg', '728.jpg', '729.jpg', '73.jpg', '730.jpg', '731.jpg', '732.jpg', '733.jpg', '734.jpg', '735.jpg', '736.jpg', '737.jpg', '738.jpg', '739.jpg', '74.jpg', '740.jpg', '741.jpg', '742.jpg', '743.jpg', '744.jpg', '745.jpg', '746.jpg', '747.jpg', '748.jpg', '749.jpg', '75.jpg', '750.jpg', '751.jpg', '752.jpg', '753.jpg', '754.jpg', '755.jpg', '756.jpg', '757.jpg', '758.jpg', '759.jpg', '76.jpg', '760.jpg', '761.jpg', '762.jpg', '763.jpg', '764.jpg', '765.jpg', '766.jpg', '767.jpg', '768.jpg', '769.jpg', '77.jpg', '770.jpg', '771.jpg', '772.jpg', '773.jpg', '774.jpg', '775.jpg', '776.jpg', '777.jpg', '778.jpg', '779.jpg', '78.jpg', '780.jpg', '781.jpg', '782.jpg', '783.jpg', '784.jpg', '785.jpg', '786.jpg', '787.jpg', '788.jpg', '789.jpg', '79.jpg', '790.jpg', '791.jpg', '792.jpg', '793.jpg', '794.jpg', '795.jpg', '796.jpg', '797.jpg', '798.jpg', '799.jpg', '8.jpg', '80.jpg', '800.jpg', '801.jpg', '802.jpg', '803.jpg', '804.jpg', '805.jpg', '806.jpg', '807.jpg', '808.jpg', '809.jpg', '81.jpg', '810.jpg', '811.jpg', '812.jpg', '813.jpg', '814.jpg', '815.jpg', '816.jpg', '817.jpg', '818.jpg', '819.jpg', '82.jpg', '820.jpg', '821.jpg', '822.jpg', '823.jpg', '824.jpg', '825.jpg', '826.jpg', '827.jpg', '828.jpg', '829.jpg', '83.jpg', '830.jpg', '831.jpg', '832.jpg', '833.jpg', '834.jpg', '835.jpg', '836.jpg', '837.jpg', '838.jpg', '839.jpg', '84.jpg', '840.jpg', '841.jpg', '842.jpg', '843.jpg', '844.jpg', '845.jpg', '846.jpg', '847.jpg', '848.jpg', '849.jpg', '85.jpg', '850.jpg', '851.jpg', '852.jpg', '853.jpg', '854.jpg', '855.jpg', '856.jpg', '857.jpg', '858.jpg', '859.jpg', '86.jpg', '860.jpg', '861.jpg', '862.jpg', '863.jpg', '864.jpg', '865.jpg', '866.jpg', '867.jpg', '868.jpg', '869.jpg', '87.jpg', '870.jpg', '871.jpg', '872.jpg', '873.jpg', '874.jpg', '875.jpg', '876.jpg', '877.jpg', '878.jpg', '879.jpg', '88.jpg', '880.jpg', '881.jpg', '882.jpg', '883.jpg', '884.jpg', '885.jpg', '886.jpg', '887.jpg', '888.jpg', '889.jpg', '89.jpg', '890.jpg', '891.jpg', '892.jpg', '893.jpg', '894.jpg', '895.jpg', '896.jpg', '897.jpg', '898.jpg', '899.jpg', '9.jpg', '90.jpg', '900.jpg', '901.jpg', '902.jpg', '903.jpg', '904.jpg', '905.jpg', '906.jpg', '907.jpg', '908.jpg', '909.jpg', '91.jpg', '910.jpg', '911.jpg', '912.jpg', '913.jpg', '914.jpg', '915.jpg', '916.jpg', '917.jpg', '918.jpg', '919.jpg', '92.jpg', '920.jpg', '921.jpg', '922.jpg', '923.jpg', '924.jpg', '925.jpg', '926.jpg', '927.jpg', '928.jpg', '929.jpg', '93.jpg', '930.jpg', '931.jpg', '932.jpg', '933.jpg', '934.jpg', '935.jpg', '936.jpg', '937.jpg', '938.jpg', '939.jpg', '94.jpg', '940.jpg', '941.jpg', '942.jpg', '943.jpg', '944.jpg', '945.jpg', '946.jpg', '947.jpg', '948.jpg', '949.jpg', '95.jpg', '950.jpg', '951.jpg', '952.jpg', '953.jpg', '954.jpg', '955.jpg', '956.jpg', '957.jpg', '958.jpg', '959.jpg', '96.jpg', '960.jpg', '961.jpg', '962.jpg', '963.jpg', '964.jpg', '965.jpg', '966.jpg', '967.jpg', '968.jpg', '969.jpg', '97.jpg', '970.jpg', '971.jpg', '972.jpg', '973.jpg', '974.jpg', '975.jpg', '976.jpg', '977.jpg', '978.jpg', '979.jpg', '98.jpg', '980.jpg', '981.jpg', '982.jpg', '983.jpg', '984.jpg', '985.jpg', '986.jpg', '987.jpg', '988.jpg', '989.jpg', '99.jpg', '990.jpg', '991.jpg', '992.jpg', '993.jpg', '994.jpg', '995.jpg', '996.jpg', '997.jpg', '998.jpg', '999.jpg']\n"
     ]
    }
   ],
   "source": [
    "# 데이터가 많으므로 테스트에서는 1000건만 처리하도록 한다.\n",
    "NUM_ROWS = 1000\n",
    "\n",
    "DATASET_PATH = 'C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷'\n",
    "print(os.listdir(DATASET_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2eb3b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>548.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>124.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>320.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>172.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>360.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename                                              image\n",
       "0  540.jpg  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...\n",
       "1   69.jpg  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...\n",
       "2  548.jpg  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...\n",
       "3  137.jpg  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...\n",
       "4  169.jpg  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...\n",
       "5  124.jpg  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...\n",
       "6  320.jpg  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...\n",
       "7  172.jpg  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...\n",
       "8  360.jpg  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/...\n",
       "9    6.jpg  C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = []\n",
    "filenames = []\n",
    "images = []\n",
    "\n",
    "df = pd.DataFrame(columns=['filename', 'image'])\n",
    "for folder in os.listdir(DATASET_PATH):\n",
    "    for file in os.listdir(os.path.join(DATASET_PATH, folder)):\n",
    "#         categories.append(folder)\n",
    "        filenames.append(file)\n",
    "        images.append(os.path.join(DATASET_PATH, folder, file))\n",
    "\n",
    "df['filename'] = filenames\n",
    "df['image'] = images\n",
    "\n",
    "df = df.iloc[np.random.permutation(df.index)].reset_index(drop=True)\n",
    "df = df[:NUM_ROWS]\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "949222ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딕셔너리 데이터를 인자값을 받아서 이미지를 출력한다.\n",
    "def plot_figures(figures, nrows = 1, ncols=1,figsize=(5, 3)):\n",
    "    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=figsize)\n",
    "    for ind,title in enumerate(figures):\n",
    "        axeslist.ravel()[ind].imshow(cv2.cvtColor(figures[title], cv2.COLOR_BGR2RGB))\n",
    "        axeslist.ravel()[ind].set_title(title)\n",
    "        axeslist.ravel()[ind].set_axis_off()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "353db0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 경로를 읽어서 numpy로 변환한다.\n",
    "# 기본 0.1 비율로 리사이즈를 처리한다.\n",
    "def load_image(img_path, resized_fac = 0.1):\n",
    "    img  = cv2.imread(img_path)\n",
    "    w, h, _ = img.shape\n",
    "    resized = cv2.resize(img, (int(h*resized_fac), int(w*resized_fac)), interpolation = cv2.INTER_AREA)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "865a5030",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m figures \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) : load_image(row\u001b[38;5;241m.\u001b[39mimage) \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39miterrows()}\n\u001b[0;32m      2\u001b[0m figures\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m      3\u001b[0m plot_figures(figures, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m figures \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) : \u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39miterrows()}\n\u001b[0;32m      2\u001b[0m figures\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m      3\u001b[0m plot_figures(figures, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[1;32mIn[35], line 5\u001b[0m, in \u001b[0;36mload_image\u001b[1;34m(img_path, resized_fac)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_image\u001b[39m(img_path, resized_fac \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m):\n\u001b[0;32m      4\u001b[0m     img  \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[1;32m----> 5\u001b[0m     w, h, _ \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[0;32m      6\u001b[0m     resized \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (\u001b[38;5;28mint\u001b[39m(h\u001b[38;5;241m*\u001b[39mresized_fac), \u001b[38;5;28mint\u001b[39m(w\u001b[38;5;241m*\u001b[39mresized_fac)), interpolation \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mINTER_AREA)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resized\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "figures = {'sample'+ str(i) : load_image(row.image) for i, row in df.sample(6).iterrows()}\n",
    "figures.keys()\n",
    "plot_figures(figures, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3e5c833",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "# from keras.preprocessing import image\n",
    "import keras.utils as image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f3088e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ResNet50' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m img_width, img_height, img_channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 훈련된 모델 사용\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mResNet50\u001b[49m(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m, include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, input_shape \u001b[38;5;241m=\u001b[39m (img_width, img_height, img_channel))\n\u001b[0;32m      7\u001b[0m base_model\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     10\u001b[0m     base_model,\n\u001b[0;32m     11\u001b[0m     GlobalMaxPooling2D()\n\u001b[0;32m     12\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ResNet50' is not defined"
     ]
    }
   ],
   "source": [
    "# 입력 이미지\n",
    "\n",
    "img_width, img_height, img_channel = 224, 224, 3\n",
    "\n",
    "# 훈련된 모델 사용\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape = (img_width, img_height, img_channel))\n",
    "base_model.trainable = False\n",
    "\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    GlobalMaxPooling2D()\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2def4c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 임베딩\n",
    "def get_embedding(model, img_path):\n",
    "    # Pillow 이미지 로드\n",
    "    img = image.load_img(img_path, target_size=(img_width, img_height))\n",
    "    # numpy 데이터로 변환 (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # 차원을 추가해준다. (1, 224, 224, 3)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    # 1차원의 배열로 재배열해준다. [[5.232, 2.12, ...]] -> [5.232, 2.12, ...]\n",
    "    return model.predict(x).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a651a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/tiger/OneDrive/바탕 화면/deep_daiv/추천시스템/challenge/옷\\\\상의\\\\439.jpg'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c334c5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 첫 행 이미지 임베딩을 출력\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m emb \u001b[38;5;241m=\u001b[39m get_embedding(\u001b[43mmodel\u001b[49m, df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mimage)\n\u001b[0;32m      3\u001b[0m emb\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 첫 행 이미지 임베딩을 출력\n",
    "emb = get_embedding(model, df.iloc[0].image)\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29df4919",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 첫 행 이미지 시각화\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m img_array \u001b[38;5;241m=\u001b[39m \u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(cv2\u001b[38;5;241m.\u001b[39mcvtColor(img_array, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m, in \u001b[0;36mload_image\u001b[1;34m(img_path, resized_fac)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_image\u001b[39m(img_path, resized_fac \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m):\n\u001b[0;32m      4\u001b[0m     img  \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[1;32m----> 5\u001b[0m     w, h, _ \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[0;32m      6\u001b[0m     resized \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (\u001b[38;5;28mint\u001b[39m(h\u001b[38;5;241m*\u001b[39mresized_fac), \u001b[38;5;28mint\u001b[39m(w\u001b[38;5;241m*\u001b[39mresized_fac)), interpolation \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mINTER_AREA)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resized\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# 첫 행 이미지 시각화\n",
    "img_array = load_image(df.iloc[0].image)\n",
    "plt.figure(figsize = (2,2))\n",
    "plt.imshow(cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB))\n",
    "print(img_array.shape)\n",
    "print(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24570f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "1it [00:00, 1002.46it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:6\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\std.py:814\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(df, df_function)(wrapper, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    816\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\std.py:809\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    804\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[0;32m    808\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m<timed exec>:6\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(img)\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "tqdm_pandas(tqdm())\n",
    "\n",
    "# 전체 데이터 임베딩\n",
    "df_sample = df\n",
    "map_embeddings = df_sample['image'].progress_apply(lambda img: get_embedding(model, img))\n",
    "df_embs = map_embeddings.apply(pd.Series)\n",
    "\n",
    "print(df_embs.shape)\n",
    "df_embs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "769624cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aecd8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# cosine 거리 계산\n",
    "pairwise_distances(df_embs, metric='cosine')\n",
    "\n",
    "# 정규화\n",
    "cosine_sim = 1 - pairwise_distances(df_embs, metric='cosine')\n",
    "cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8245348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사한 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7276e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(range(len(df)), index=df.index)\n",
    "\n",
    "def get_recommender(idx, df, top_n = 5):\n",
    "    sim_idx = indices[idx]\n",
    "    sim_scores = list(enumerate(cosine_sim[sim_idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:top_n+1]\n",
    "    idx_rec    = [i[0] for i in sim_scores]\n",
    "    idx_sim    = [i[1] for i in sim_scores]\n",
    "\n",
    "    return indices.iloc[idx_rec].index, idx_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e88494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사한 데이터 출력해보기\n",
    "idx_ref = 1\n",
    "idx_rec, idx_sim = get_recommender(idx_ref, df, top_n = 6)\n",
    "\n",
    "plt.figure(figsize = (2,2))\n",
    "plt.imshow(cv2.cvtColor(load_image(df.iloc[idx_ref].image), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "figures = {'img-'+str(i): load_image(row.image) for i, row in df.loc[idx_rec].iterrows()}\n",
    "plot_figures(figures, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324fa2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d11e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
